{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "import math\n",
    "import scipy as sp\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(file_name) -> pd.DataFrame:\n",
    "    \"\"\"Loading dataset\n",
    "    @param file_name: user input dataset\n",
    "    @return: dataset\n",
    "    \"\"\"\n",
    "    if os.path.exists(file_name) == False:\n",
    "        raise ValueError(\"File not found\")\n",
    "    dataset = pd.read_csv(file_name)\n",
    "    return dataset\n",
    "\n",
    "def copy_df(df) -> pd.DataFrame:\n",
    "    \"\"\"copy df to new temp df\n",
    "    @param df: user input dataset\n",
    "    @return: new df\n",
    "    \"\"\"\n",
    "    return df.copy(deep=True)\n",
    "\n",
    "def normalize_missing_values(dataset) -> pd.DataFrame:\n",
    "    \"\"\"normalize dataset missing values with mean for numerical columns\n",
    "    @param dataset: user input dataset\n",
    "    @return: normalized dataset\n",
    "    \"\"\"\n",
    "    for col in dataset.columns:\n",
    "        # print(\"column: \",col, \"type: \", dataset[col].dtype)\n",
    "        if dataset[col].dtype == 'object':\n",
    "            dataset[col] = dataset[col].fillna(method='bfill')\n",
    "        else:\n",
    "            dataset[col] = dataset[col].fillna(dataset[col].mean()) \n",
    "    return dataset\n",
    "\n",
    "# change column order to get label at the end\n",
    "def change_column_order(data, first_column_name, second_column_name) -> pd.DataFrame:\n",
    "    \"\"\"change column order\n",
    "    @param dataset: user input dataset\n",
    "    @param first_column: first column name\n",
    "    @param second_column: second column name\n",
    "    @return: dataset with new column order\n",
    "    \"\"\"\n",
    "    temp_df = copy_df(data)\n",
    "    data.drop(first_column_name, axis=1, inplace=True)\n",
    "    data.drop(second_column_name, axis=1, inplace=True)\n",
    "    data = temp_df[[*data.columns, second_column_name, first_column_name]]\n",
    "    return data\n",
    "\n",
    "def print_dataset(dataset) -> None:\n",
    "    \"\"\"print dataset inforamtion\n",
    "    @param dataset: user input dataset\n",
    "    @return: print dataset information via head(), info(), shape()\n",
    "    \"\"\"\n",
    "    print(dataset.head())\n",
    "    print(dataset.info())\n",
    "    print(dataset.describe())\n",
    "    print(dataset.columns)\n",
    "    print(dataset.iloc[:, -2].value_counts())\n",
    "\n",
    "def dummy_variable_indicator(data, column_name) -> pd.DataFrame:\n",
    "    \"\"\"dummy variable indicator\n",
    "    @param data: user input data\n",
    "    @param column_name: column name\n",
    "    @return: data with dummy variable indicator\n",
    "    \"\"\"\n",
    "    if column_name not in data.columns:\n",
    "        raise ValueError(\"Column not found\")\n",
    "    data = pd.get_dummies(data, columns=[column_name])\n",
    "    return data\n",
    "\n",
    "def remove_column(data, column_name) -> pd.DataFrame:\n",
    "    \"\"\"remove column\n",
    "    @param data: user input data\n",
    "    @param column_name: column name\n",
    "    @return: data without column\n",
    "    \"\"\"\n",
    "    if column_name not in data.columns:\n",
    "        raise ValueError(\"Column not found\")\n",
    "    data = data.drop(column_name, axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
      "0    -122.23     37.88                41.0        880.0           129.0   \n",
      "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
      "2    -122.24     37.85                52.0       1467.0           190.0   \n",
      "3    -122.25     37.85                52.0       1274.0           235.0   \n",
      "4    -122.25     37.85                52.0       1627.0           280.0   \n",
      "\n",
      "   population  households  median_income ocean_proximity  median_house_value  \n",
      "0       322.0       126.0         8.3252        NEAR BAY            452600.0  \n",
      "1      2401.0      1138.0         8.3014        NEAR BAY            358500.0  \n",
      "2       496.0       177.0         7.2574        NEAR BAY            352100.0  \n",
      "3       558.0       219.0         5.6431        NEAR BAY            341300.0  \n",
      "4       565.0       259.0         3.8462        NEAR BAY            342200.0  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 10 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   longitude           20640 non-null  float64\n",
      " 1   latitude            20640 non-null  float64\n",
      " 2   housing_median_age  20640 non-null  float64\n",
      " 3   total_rooms         20640 non-null  float64\n",
      " 4   total_bedrooms      20640 non-null  float64\n",
      " 5   population          20640 non-null  float64\n",
      " 6   households          20640 non-null  float64\n",
      " 7   median_income       20640 non-null  float64\n",
      " 8   ocean_proximity     20640 non-null  object \n",
      " 9   median_house_value  20640 non-null  float64\n",
      "dtypes: float64(9), object(1)\n",
      "memory usage: 1.6+ MB\n",
      "None\n",
      "          longitude      latitude  housing_median_age   total_rooms  \\\n",
      "count  20640.000000  20640.000000        20640.000000  20640.000000   \n",
      "mean    -119.569704     35.631861           28.639486   2635.763081   \n",
      "std        2.003532      2.135952           12.585558   2181.615252   \n",
      "min     -124.350000     32.540000            1.000000      2.000000   \n",
      "25%     -121.800000     33.930000           18.000000   1447.750000   \n",
      "50%     -118.490000     34.260000           29.000000   2127.000000   \n",
      "75%     -118.010000     37.710000           37.000000   3148.000000   \n",
      "max     -114.310000     41.950000           52.000000  39320.000000   \n",
      "\n",
      "       total_bedrooms    population    households  median_income  \\\n",
      "count    20640.000000  20640.000000  20640.000000   20640.000000   \n",
      "mean       537.870553   1425.476744    499.539680       3.870671   \n",
      "std        419.266592   1132.462122    382.329753       1.899822   \n",
      "min          1.000000      3.000000      1.000000       0.499900   \n",
      "25%        297.000000    787.000000    280.000000       2.563400   \n",
      "50%        438.000000   1166.000000    409.000000       3.534800   \n",
      "75%        643.250000   1725.000000    605.000000       4.743250   \n",
      "max       6445.000000  35682.000000   6082.000000      15.000100   \n",
      "\n",
      "       median_house_value  \n",
      "count        20640.000000  \n",
      "mean        206855.816909  \n",
      "std         115395.615874  \n",
      "min          14999.000000  \n",
      "25%         119600.000000  \n",
      "50%         179700.000000  \n",
      "75%         264725.000000  \n",
      "max         500001.000000  \n",
      "Index(['longitude', 'latitude', 'housing_median_age', 'total_rooms',\n",
      "       'total_bedrooms', 'population', 'households', 'median_income',\n",
      "       'ocean_proximity', 'median_house_value'],\n",
      "      dtype='object')\n",
      "<1H OCEAN     9136\n",
      "INLAND        6551\n",
      "NEAR OCEAN    2658\n",
      "NEAR BAY      2290\n",
      "ISLAND           5\n",
      "Name: ocean_proximity, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "dataset = load(\"housing.csv\")\n",
    "dataset = normalize_missing_values(dataset)\n",
    "dataset = change_column_order(dataset, \"median_house_value\", \"ocean_proximity\")\n",
    "print_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
      "0    -122.23     37.88                41.0        880.0           129.0   \n",
      "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
      "2    -122.24     37.85                52.0       1467.0           190.0   \n",
      "3    -122.25     37.85                52.0       1274.0           235.0   \n",
      "4    -122.25     37.85                52.0       1627.0           280.0   \n",
      "\n",
      "   population  households  median_income  median_house_value  \\\n",
      "0       322.0       126.0         8.3252            452600.0   \n",
      "1      2401.0      1138.0         8.3014            358500.0   \n",
      "2       496.0       177.0         7.2574            352100.0   \n",
      "3       558.0       219.0         5.6431            341300.0   \n",
      "4       565.0       259.0         3.8462            342200.0   \n",
      "\n",
      "   ocean_proximity_<1H OCEAN  ocean_proximity_ISLAND  \\\n",
      "0                          0                       0   \n",
      "1                          0                       0   \n",
      "2                          0                       0   \n",
      "3                          0                       0   \n",
      "4                          0                       0   \n",
      "\n",
      "   ocean_proximity_NEAR BAY  ocean_proximity_NEAR OCEAN  \n",
      "0                         1                           0  \n",
      "1                         1                           0  \n",
      "2                         1                           0  \n",
      "3                         1                           0  \n",
      "4                         1                           0  \n"
     ]
    }
   ],
   "source": [
    "dataset = dummy_variable_indicator(dataset, \"ocean_proximity\")\n",
    "data = remove_column(dataset, \"ocean_proximity_INLAND\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset into train, validation and test - 80% train, 10% validation and 10% test with sklearn\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "temp_data = copy_df(dataset)\n",
    "X = temp_data.drop('median_house_value', axis=1)\n",
    "y = temp_data[['median_house_value']]\n",
    "feature_columns = list(X.columns)\n",
    "\n",
    "# split = StratifiedShuffleSplit(n_splits=1, test_size=0.4, random_state=42)\n",
    "# for train_index, test_valid_index in split.split(dataset, dataset.iloc[:, -1:]):\n",
    "#     train_set = dataset.iloc[train_index]\n",
    "#     test_valid_set = dataset.iloc[test_valid_index]\n",
    "\n",
    "# split2 = StratifiedShuffleSplit(n_splits=1, test_size=0.5, random_state=42)\n",
    "# for test_index, valid_index in split2.split(test_valid_set, test_valid_set.iloc[:, -1:]):\n",
    "#     test_set = test_valid_set.iloc[test_index]\n",
    "#     valid_set = test_valid_set.iloc[valid_index]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "temp_data = copy_df(dataset)\n",
    "X = temp_data.drop('median_house_value', axis=1)\n",
    "y = temp_data[['median_house_value']]\n",
    "feature_columns = list(X.columns)\n",
    "\n",
    "SEED = 2000\n",
    "x_train, x_validation_and_test, y_train, y_validation_and_test = train_test_split(X, y, test_size=.4, random_state=SEED)\n",
    "x_validation, x_test, y_validation, y_test = train_test_split(x_validation_and_test, y_validation_and_test, test_size=.5, random_state=SEED)\n",
    "\n",
    "# print(x_train.head(), y_train.head())\n",
    "# print(x_validation.head(), y_validation.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train_list[ 0 ]:  (12384, 9) y_train_list[ 0 ]:  (12384, 1)\n",
      "x_validation_list[ 0 ]:  (4128, 9) y_validation_list[ 0 ]:  (4128, 1)\n",
      "x_test_list[ 0 ]:  (4128, 9) y_test_list[ 0 ]:  (4128, 1)\n",
      "sum: 20640\n",
      "x_train_list[ 1 ]:  (12384, 9) y_train_list[ 1 ]:  (12384, 1)\n",
      "x_validation_list[ 1 ]:  (4128, 9) y_validation_list[ 1 ]:  (4128, 1)\n",
      "x_test_list[ 1 ]:  (4128, 9) y_test_list[ 1 ]:  (4128, 1)\n",
      "sum: 20640\n",
      "x_train_list[ 2 ]:  (12384, 9) y_train_list[ 2 ]:  (12384, 1)\n",
      "x_validation_list[ 2 ]:  (4128, 9) y_validation_list[ 2 ]:  (4128, 1)\n",
      "x_test_list[ 2 ]:  (4128, 9) y_test_list[ 2 ]:  (4128, 1)\n",
      "sum: 20640\n"
     ]
    }
   ],
   "source": [
    "def train_test_split(data, train_size=None, test_size=None, random_state=None, shuffle=None) -> tuple:\n",
    "    \"\"\"split dataset into train, validation and test\n",
    "    @param data: user input dataset\n",
    "    @param train_size: user input train size\n",
    "    @param test_size: user input test size\n",
    "    @param random_state: user input random state\n",
    "    @return: train, validation and test dataset\n",
    "    \"\"\"\n",
    "    if train_size is None and test_size is None:\n",
    "        raise ValueError(\"train_size and test_size can not be both None\")\n",
    "    if train_size is not None and test_size is not None and train_size + test_size > 1:\n",
    "        raise ValueError(\"train_size and test_size sum must be equal to 1\")\n",
    "    if train_size is not None and test_size is not None and train_size + test_size < 1:\n",
    "        raise ValueError(\"train_size and test_size sum is not equal to one\")\n",
    "    if train_size is not None:\n",
    "        if train_size <= 0:\n",
    "            raise ValueError(\"train_size must be greater than 0\")\n",
    "        if train_size >= 1:\n",
    "            raise ValueError(\"train_size must be less than 1\")\n",
    "        if test_size is None:\n",
    "            test_size = 1 - train_size\n",
    "        elif test_size <= 0:\n",
    "            raise ValueError(\"test_size must be greater than 0\")\n",
    "        elif test_size >= 1:\n",
    "            raise ValueError(\"test_size must be less than 1\")\n",
    "    if test_size is not None:\n",
    "        if test_size <= 0:\n",
    "            raise ValueError(\"test_size must be greater than 0\")\n",
    "        if test_size >= 1:\n",
    "            raise ValueError(\"test_size must be less than 1\")\n",
    "        if train_size is None:\n",
    "            train_size = 1 - test_size\n",
    "        elif train_size <= 0:\n",
    "            raise ValueError(\"train_size must be greater than 0\")\n",
    "        elif train_size >= 1:\n",
    "            raise ValueError(\"train_size must be less than 1\")\n",
    "    train_size = int(len(data) * train_size)\n",
    "    test_size = int(len(data) * test_size)\n",
    "    if shuffle is True:\n",
    "        data = data.sample(frac=1).reset_index(drop=True)\n",
    "    # print(\"train_size: \", train_size, \"test_size: \", test_size, 'sum: ', train_size + test_size)\n",
    "    train_index = np.random.choice(len(data), train_size, replace=False)\n",
    "    x_train = data.drop('median_house_value', axis=1).iloc[train_index].reset_index(drop=True)\n",
    "    y_train = data.iloc[train_index, -1:].reset_index(drop=True)\n",
    "    test_index = np.setdiff1d(np.arange(len(data)), train_index)\n",
    "    x_test = data.drop('median_house_value', axis=1).iloc[test_index].reset_index(drop=True)\n",
    "    y_test = data.iloc[test_index, -1:].reset_index(drop=True)\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "def concat_data(x_data, y_data) -> list:\n",
    "    \"\"\"\n",
    "    @param x_data: feature data\n",
    "    @param y_data: label data\n",
    "    @return: concatenation of features and label data\n",
    "    \"\"\"\n",
    "    return pd.concat([x_data, y_data], axis=1)\n",
    "\n",
    "def k_fold(data, k_fold_number):\n",
    "    \"\"\" K-fold data using train_test_split function\n",
    "    @param data: user input dataset\n",
    "    @param k_fold_number: number of folds\n",
    "    @return: train, validation and test dataset\n",
    "    \"\"\"\n",
    "    x_train_list, x_test_list, y_train_list, y_test_list, x_validation_list, y_validation_list  = [], [], [], [], [], []\n",
    "    for _ in range(k_fold_number):\n",
    "        x_train,y_train, x_validation_test, y_validation_test = train_test_split(copy_df(data), train_size=.6, shuffle=True)\n",
    "        x_validation, y_validation, x_test, y_test = train_test_split(concat_data(x_validation_test, y_validation_test), test_size=.5, shuffle=True)\n",
    "        x_train_list.append(x_train)\n",
    "        x_test_list.append(x_test)\n",
    "        y_train_list.append(y_train)\n",
    "        y_test_list.append(y_test)\n",
    "        x_validation_list.append(x_validation)\n",
    "        y_validation_list.append(y_validation)\n",
    "    return x_train_list, y_train_list, x_test_list, y_test_list, x_validation_list, y_validation_list\n",
    "\n",
    "# 60% train, 20% validation and 20% test\n",
    "k_fold_number = 3\n",
    "x_train_list, y_train_list, x_test_list, y_test_list, x_validation_list, y_validation_list = k_fold(copy_df(dataset), k_fold_number)\n",
    "\n",
    "for index in range(k_fold_number):\n",
    "    print(\"x_train_list[\", index, \"]: \", x_train_list[index].shape, \"y_train_list[\", index, \"]: \", y_train_list[index].shape)\n",
    "    print(\"x_validation_list[\", index, \"]: \", x_validation_list[index].shape, \"y_validation_list[\", index, \"]: \", y_validation_list[index].shape)\n",
    "    print(\"x_test_list[\", index, \"]: \", x_test_list[index].shape, \"y_test_list[\", index, \"]: \", y_test_list[index].shape)\n",
    "    print(f\"sum: {x_train_list[index].shape[0] + x_validation_list[index].shape[0] + x_test_list[index].shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train_list[0]:     longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
      "0    -118.28     34.05                31.0       1525.0           730.0   \n",
      "1    -118.10     33.84                36.0        690.0           109.0   \n",
      "2    -117.90     34.12                33.0       1788.0           456.0   \n",
      "3    -116.92     32.82                34.0       1765.0           284.0   \n",
      "4    -117.87     33.63                 9.0       6163.0          1004.0   \n",
      "\n",
      "   population  households  median_income ocean_proximity  \n",
      "0      2510.0       652.0         1.6355       <1H OCEAN  \n",
      "1       316.0       104.0         3.7813       <1H OCEAN  \n",
      "2      1787.0       361.0         2.6629       <1H OCEAN  \n",
      "3       772.0       282.0         5.0118       <1H OCEAN  \n",
      "4      1912.0       903.0        10.8289       <1H OCEAN   \n",
      "y_train_list[0]:     median_house_value\n",
      "0            162500.0\n",
      "1            209100.0\n",
      "2            124100.0\n",
      "3            165300.0\n",
      "4            500001.0\n",
      "x_validation_list[0]:     longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
      "0    -117.93     33.93                25.0       2431.0           534.0   \n",
      "1    -122.25     37.47                38.0        645.0           124.0   \n",
      "2    -121.37     38.56                18.0       2129.0           363.0   \n",
      "3    -117.99     34.12                35.0       1040.0           231.0   \n",
      "4    -118.30     34.26                28.0       1643.0           489.0   \n",
      "\n",
      "   population  households  median_income ocean_proximity  \n",
      "0      1702.0       523.0         3.7933       <1H OCEAN  \n",
      "1       265.0       103.0         5.4688      NEAR OCEAN  \n",
      "2       815.0       347.0         2.7679          INLAND  \n",
      "3      1040.0       242.0         2.5395          INLAND  \n",
      "4      1142.0       458.0         3.1607       <1H OCEAN   \n",
      "y_validation_list[0]:     median_house_value\n",
      "0            184400.0\n",
      "1            305000.0\n",
      "2            118000.0\n",
      "3            139200.0\n",
      "4            200600.0\n",
      "x_test_list[0]:     longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
      "0    -121.85     37.24                17.0       6425.0          1268.0   \n",
      "1    -118.24     33.93                37.0       1027.0           258.0   \n",
      "2    -117.90     33.98                20.0       9893.0          2283.0   \n",
      "3    -117.93     33.88                52.0       2157.0           362.0   \n",
      "4    -118.38     34.11                38.0       2601.0           523.0   \n",
      "\n",
      "   population  households  median_income ocean_proximity  \n",
      "0      3934.0      1238.0         5.1228       <1H OCEAN  \n",
      "1       824.0       248.0         1.5132       <1H OCEAN  \n",
      "2      7228.0      2159.0         3.2530       <1H OCEAN  \n",
      "3      1001.0       373.0         5.1237       <1H OCEAN  \n",
      "4       870.0       474.0         7.1134       <1H OCEAN   \n",
      "y_test_list[0]:     median_house_value\n",
      "0            237600.0\n",
      "1             86300.0\n",
      "2            186700.0\n",
      "3            240000.0\n",
      "4            416700.0\n"
     ]
    }
   ],
   "source": [
    "#print head()s for index 0\n",
    "print(\"x_train_list[0]: \", x_train_list[0].head(), \"\\ny_train_list[0]: \", y_train_list[0].head())\n",
    "print(\"x_validation_list[0]: \", x_validation_list[0].head(), \"\\ny_validation_list[0]: \", y_validation_list[0].head())\n",
    "print(\"x_test_list[0]: \", x_test_list[0].head(), \"\\ny_test_list[0]: \", y_test_list[0].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "74e8ec9c84b340f4de24eed72001e08faf7103697f715d0f05647d14de0826d0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('RT-Academy': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
